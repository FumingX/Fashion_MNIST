{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashion/train-images-idx3-ubyte.gz\n",
      "Extracting fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting fashion/t10k-labels-idx1-ubyte.gz\n",
      "number of convolution layers per block: 16\n",
      "convolution 1 size: (28, 28, 32)\n",
      "convolution 2 size: (28, 28, 32)\n",
      "convolution 3 size: (14, 14, 64)\n",
      "convolution 4 size: (7, 7, 128)\n",
      "average pooling size: (128,)\n",
      "flatten size: (128,)\n",
      "fc size: (10,)\n",
      "softmax size: (10,)\n",
      "Build complete.\n"
     ]
    }
   ],
   "source": [
    "from Trainer import ResNetTrainer\n",
    "trainer = ResNetTrainer(resnet_size=56, batch_size=128, epoch=500, learn_rate=0.01, momentum=0.9)\n",
    "trainer.set_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch: 1, loss: 990.8449420928955\n",
      "validation accuracy: 0.0914\n",
      "train accuracy: 0.10078181818073446\n",
      "\n",
      "epoch: 2, loss: 957.7789137363434\n",
      "validation accuracy: 0.2822\n",
      "train accuracy: 0.2869090908917514\n",
      "\n",
      "epoch: 3, loss: 864.0654757022858\n",
      "validation accuracy: 0.5196\n",
      "train accuracy: 0.5189272727272727\n",
      "\n",
      "epoch: 4, loss: 800.9034593105316\n",
      "validation accuracy: 0.5894\n",
      "train accuracy: 0.5879636364069852\n",
      "\n",
      "epoch: 5, loss: 786.2001923322678\n",
      "validation accuracy: 0.6592\n",
      "train accuracy: 0.6552727272900668\n",
      "\n",
      "epoch: 6, loss: 768.015198469162\n",
      "validation accuracy: 0.683\n",
      "train accuracy: 0.677545454528115\n",
      "\n",
      "epoch: 7, loss: 760.3132699728012\n",
      "validation accuracy: 0.6948\n",
      "train accuracy: 0.69009090905623\n",
      "\n",
      "epoch: 8, loss: 752.1427539587021\n",
      "validation accuracy: 0.7102\n",
      "train accuracy: 0.708527272753282\n",
      "\n",
      "epoch: 9, loss: 747.5533293485641\n",
      "validation accuracy: 0.7154\n",
      "train accuracy: 0.7153090909177606\n",
      "\n",
      "epoch: 10, loss: 734.9398268461227\n",
      "validation accuracy: 0.7562\n",
      "train accuracy: 0.7585636364069852\n",
      "\n",
      "epoch: 11, loss: 723.1428490877151\n",
      "validation accuracy: 0.7812\n",
      "train accuracy: 0.7817454545107755\n",
      "\n",
      "epoch: 12, loss: 719.9230040311813\n",
      "validation accuracy: 0.7576\n",
      "train accuracy: 0.7582545454545454\n",
      "\n",
      "epoch: 13, loss: 715.7480057477951\n",
      "validation accuracy: 0.7952\n",
      "train accuracy: 0.800672727281397\n",
      "\n",
      "epoch: 14, loss: 715.1632252931595\n",
      "validation accuracy: 0.7948\n",
      "train accuracy: 0.7967090908830816\n",
      "\n",
      "epoch: 15, loss: 711.4858535528183\n",
      "validation accuracy: 0.7928\n",
      "train accuracy: 0.7949818181731484\n",
      "\n",
      "epoch: 16, loss: 710.3273153305054\n",
      "validation accuracy: 0.7924\n",
      "train accuracy: 0.7972545454111967\n",
      "\n",
      "epoch: 17, loss: 707.6277921199799\n",
      "validation accuracy: 0.7898\n",
      "train accuracy: 0.7889636363549666\n",
      "\n",
      "epoch: 18, loss: 707.2762036323547\n",
      "validation accuracy: 0.8106\n",
      "train accuracy: 0.8131818181558089\n",
      "\n",
      "epoch: 19, loss: 705.4729920625687\n",
      "validation accuracy: 0.7982\n",
      "train accuracy: 0.8072181818095121\n",
      "\n",
      "epoch: 20, loss: 702.917034983635\n",
      "validation accuracy: 0.8068\n",
      "train accuracy: 0.8121272726839239\n",
      "\n",
      "epoch: 21, loss: 701.9218069314957\n",
      "validation accuracy: 0.8064\n",
      "train accuracy: 0.8096181817921725\n",
      "\n",
      "epoch: 22, loss: 701.721892118454\n",
      "validation accuracy: 0.8162\n",
      "train accuracy: 0.8227090908657421\n",
      "\n",
      "epoch: 23, loss: 701.3137066364288\n",
      "validation accuracy: 0.8188\n",
      "train accuracy: 0.8261818181384694\n",
      "\n",
      "epoch: 24, loss: 700.4608145952225\n",
      "validation accuracy: 0.8068\n",
      "train accuracy: 0.8173999999739907\n",
      "\n",
      "epoch: 25, loss: 701.3686584234238\n",
      "validation accuracy: 0.8152\n",
      "train accuracy: 0.8217818181384694\n",
      "\n",
      "epoch: 26, loss: 700.6460453271866\n",
      "validation accuracy: 0.8224\n",
      "train accuracy: 0.8307818181558089\n",
      "\n",
      "epoch: 27, loss: 699.1656212806702\n",
      "validation accuracy: 0.8158\n",
      "train accuracy: 0.8300727272293784\n",
      "\n",
      "epoch: 28, loss: 697.5387139320374\n",
      "validation accuracy: 0.8222\n",
      "train accuracy: 0.8348363636710427\n",
      "\n",
      "epoch: 29, loss: 696.9697299003601\n",
      "validation accuracy: 0.8226\n",
      "train accuracy: 0.836218181774833\n",
      "\n",
      "epoch: 30, loss: 695.7607265710831\n",
      "validation accuracy: 0.816\n",
      "train accuracy: 0.8295636363202875\n",
      "\n",
      "epoch: 31, loss: 695.9871851205826\n",
      "validation accuracy: 0.824\n",
      "train accuracy: 0.8385636363809759\n",
      "\n",
      "epoch: 32, loss: 694.2513399124146\n",
      "validation accuracy: 0.8138\n",
      "train accuracy: 0.8260545454285362\n",
      "\n",
      "epoch: 33, loss: 694.3649517297745\n",
      "validation accuracy: 0.8186\n",
      "train accuracy: 0.8291090909437699\n",
      "\n",
      "epoch: 34, loss: 693.6516098976135\n",
      "validation accuracy: 0.805\n",
      "train accuracy: 0.8165999999566511\n",
      "\n",
      "epoch: 35, loss: 693.7873792648315\n",
      "validation accuracy: 0.8232\n",
      "train accuracy: 0.8393454545021057\n",
      "\n",
      "epoch: 36, loss: 682.5787845849991\n",
      "validation accuracy: 0.9126\n",
      "train accuracy: 0.9225090909177607\n",
      "\n",
      "epoch: 37, loss: 662.0847092866898\n",
      "validation accuracy: 0.9118\n",
      "train accuracy: 0.9288181818268516\n",
      "\n",
      "epoch: 38, loss: 663.1917409896851\n",
      "validation accuracy: 0.91\n",
      "train accuracy: 0.9243272727186029\n",
      "\n",
      "epoch: 39, loss: 662.3234156370163\n",
      "validation accuracy: 0.9168\n",
      "train accuracy: 0.9338727272640575\n",
      "\n",
      "epoch: 40, loss: 660.2448515892029\n",
      "validation accuracy: 0.911\n",
      "train accuracy: 0.9301090908830816\n",
      "\n",
      "epoch: 41, loss: 660.2752768993378\n",
      "validation accuracy: 0.91\n",
      "train accuracy: 0.9212909090822393\n",
      "\n",
      "epoch: 42, loss: 660.0732567310333\n",
      "validation accuracy: 0.9084\n",
      "train accuracy: 0.9263999999913303\n",
      "\n",
      "epoch: 43, loss: 657.8633533716202\n",
      "validation accuracy: 0.9166\n",
      "train accuracy: 0.9361454545194452\n",
      "\n",
      "epoch: 44, loss: 657.2817327976227\n",
      "validation accuracy: 0.9058\n",
      "train accuracy: 0.9263636363549665\n",
      "\n",
      "epoch: 45, loss: 656.1263126134872\n",
      "validation accuracy: 0.9152\n",
      "train accuracy: 0.9296545454458757\n",
      "\n",
      "epoch: 46, loss: 656.4556163549423\n",
      "validation accuracy: 0.9194\n",
      "train accuracy: 0.9424181817748329\n",
      "\n",
      "epoch: 47, loss: 655.9601159095764\n",
      "validation accuracy: 0.9144\n",
      "train accuracy: 0.9388181817921725\n",
      "\n",
      "epoch: 48, loss: 656.1230531930923\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.945800000034679\n",
      "\n",
      "epoch: 49, loss: 655.0526572465897\n",
      "validation accuracy: 0.9192\n",
      "train accuracy: 0.9405818181384693\n",
      "\n",
      "epoch: 50, loss: 654.9857233762741\n",
      "validation accuracy: 0.9102\n",
      "train accuracy: 0.9337818182078275\n",
      "\n",
      "epoch: 51, loss: 656.2448962926865\n",
      "validation accuracy: 0.912\n",
      "train accuracy: 0.9328363635930148\n",
      "\n",
      "epoch: 52, loss: 655.8241041898727\n",
      "validation accuracy: 0.9166\n",
      "train accuracy: 0.944909090865742\n",
      "\n",
      "epoch: 53, loss: 655.9095840454102\n",
      "validation accuracy: 0.9194\n",
      "train accuracy: 0.9460727273074063\n",
      "\n",
      "epoch: 54, loss: 653.3511517047882\n",
      "validation accuracy: 0.9208\n",
      "train accuracy: 0.94550909094377\n",
      "\n",
      "epoch: 55, loss: 652.5047255754471\n",
      "validation accuracy: 0.9178\n",
      "train accuracy: 0.9401999999739907\n",
      "\n",
      "epoch: 56, loss: 651.7085847854614\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9535818181384693\n",
      "\n",
      "epoch: 57, loss: 652.3848102092743\n",
      "validation accuracy: 0.919\n",
      "train accuracy: 0.9445272726839239\n",
      "\n",
      "epoch: 58, loss: 653.7299888134003\n",
      "validation accuracy: 0.911\n",
      "train accuracy: 0.9343636363376271\n",
      "\n",
      "epoch: 59, loss: 654.3867009878159\n",
      "validation accuracy: 0.9172\n",
      "train accuracy: 0.9476727272293785\n",
      "\n",
      "epoch: 60, loss: 653.2070354223251\n",
      "validation accuracy: 0.9184\n",
      "train accuracy: 0.9420545454285362\n",
      "\n",
      "epoch: 61, loss: 653.0326704978943\n",
      "validation accuracy: 0.9178\n",
      "train accuracy: 0.9492181818528609\n",
      "\n",
      "epoch: 62, loss: 651.5962134599686\n",
      "validation accuracy: 0.9158\n",
      "train accuracy: 0.9483272727619518\n",
      "\n",
      "epoch: 63, loss: 651.4208291769028\n",
      "validation accuracy: 0.9202\n",
      "train accuracy: 0.9494545454111967\n",
      "\n",
      "epoch: 64, loss: 651.507868885994\n",
      "validation accuracy: 0.9216\n",
      "train accuracy: 0.9478545454111966\n",
      "\n",
      "epoch: 65, loss: 649.7615692615509\n",
      "validation accuracy: 0.918\n",
      "train accuracy: 0.9494000000346791\n",
      "\n",
      "epoch: 66, loss: 649.246394276619\n",
      "validation accuracy: 0.9192\n",
      "train accuracy: 0.9501454545627941\n",
      "\n",
      "epoch: 67, loss: 650.2844189405441\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9521636363202876\n",
      "\n",
      "epoch: 68, loss: 650.5011930465698\n",
      "validation accuracy: 0.9218\n",
      "train accuracy: 0.9522363635930148\n",
      "\n",
      "epoch: 69, loss: 650.2593424320221\n",
      "validation accuracy: 0.9188\n",
      "train accuracy: 0.9556909091082486\n",
      "\n",
      "epoch: 70, loss: 649.571125626564\n",
      "validation accuracy: 0.9144\n",
      "train accuracy: 0.9448181818528609\n",
      "\n",
      "epoch: 71, loss: 649.7849698066711\n",
      "validation accuracy: 0.9102\n",
      "train accuracy: 0.9428181818528609\n",
      "\n",
      "epoch: 72, loss: 649.596678853035\n",
      "validation accuracy: 0.92\n",
      "train accuracy: 0.95610909094377\n",
      "\n",
      "epoch: 73, loss: 646.7501382827759\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9584727272900668\n",
      "\n",
      "epoch: 74, loss: 646.5437258481979\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9598363636537032\n",
      "\n",
      "epoch: 75, loss: 646.39260160923\n",
      "validation accuracy: 0.922\n",
      "train accuracy: 0.9590545454285362\n",
      "\n",
      "epoch: 76, loss: 646.557654261589\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9615636363809759\n",
      "\n",
      "epoch: 77, loss: 645.6412426233292\n",
      "validation accuracy: 0.9252\n",
      "train accuracy: 0.9616181818528609\n",
      "\n",
      "epoch: 78, loss: 646.3093482255936\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9598000000173396\n",
      "\n",
      "epoch: 79, loss: 646.1632341146469\n",
      "validation accuracy: 0.9252\n",
      "train accuracy: 0.9629272727446122\n",
      "\n",
      "epoch: 80, loss: 644.8177968263626\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9670000000173395\n",
      "\n",
      "epoch: 81, loss: 645.158531665802\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.9578909091082486\n",
      "\n",
      "epoch: 82, loss: 646.2022918462753\n",
      "validation accuracy: 0.9206\n",
      "train accuracy: 0.9555818181991577\n",
      "\n",
      "epoch: 83, loss: 645.4030674695969\n",
      "validation accuracy: 0.92\n",
      "train accuracy: 0.9536909090475603\n",
      "\n",
      "epoch: 84, loss: 645.2237479686737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.9198\n",
      "train accuracy: 0.9573818181384693\n",
      "\n",
      "epoch: 85, loss: 645.7879484891891\n",
      "validation accuracy: 0.9202\n",
      "train accuracy: 0.9596363636710427\n",
      "\n",
      "epoch: 86, loss: 645.2057503461838\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9658545454892246\n",
      "\n",
      "epoch: 87, loss: 644.2740485668182\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9662545454285362\n",
      "\n",
      "epoch: 88, loss: 643.8554301261902\n",
      "validation accuracy: 0.9238\n",
      "train accuracy: 0.9671818181991577\n",
      "\n",
      "epoch: 89, loss: 645.2002340555191\n",
      "validation accuracy: 0.9148\n",
      "train accuracy: 0.952654545471885\n",
      "\n",
      "epoch: 90, loss: 644.3316509723663\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9671090909264305\n",
      "\n",
      "epoch: 91, loss: 643.0529000759125\n",
      "validation accuracy: 0.9272\n",
      "train accuracy: 0.9670181818355214\n",
      "\n",
      "epoch: 92, loss: 643.1151331663132\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.965054545471885\n",
      "\n",
      "epoch: 93, loss: 642.6530051231384\n",
      "validation accuracy: 0.9256\n",
      "train accuracy: 0.9711090909264305\n",
      "\n",
      "epoch: 94, loss: 642.9396255016327\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9694000000346791\n",
      "\n",
      "epoch: 95, loss: 642.2210894823074\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9682727272900669\n",
      "\n",
      "epoch: 96, loss: 642.6304296255112\n",
      "validation accuracy: 0.9248\n",
      "train accuracy: 0.9702000000173395\n",
      "\n",
      "epoch: 97, loss: 644.6207007169724\n",
      "validation accuracy: 0.9218\n",
      "train accuracy: 0.9613454545021057\n",
      "\n",
      "epoch: 98, loss: 646.429664850235\n",
      "validation accuracy: 0.9192\n",
      "train accuracy: 0.9565818181991577\n",
      "\n",
      "epoch: 99, loss: 643.8399064540863\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9687818181991578\n",
      "\n",
      "epoch: 100, loss: 641.9708415269852\n",
      "validation accuracy: 0.924\n",
      "train accuracy: 0.9699818181558089\n",
      "\n",
      "epoch: 101, loss: 641.4083125591278\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9706363636537032\n",
      "\n",
      "epoch: 102, loss: 641.3075087070465\n",
      "validation accuracy: 0.9256\n",
      "train accuracy: 0.9724181818528609\n",
      "\n",
      "epoch: 103, loss: 640.0642424821854\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9763454545801337\n",
      "\n",
      "epoch: 104, loss: 640.3392595052719\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9753090909437699\n",
      "\n",
      "epoch: 105, loss: 639.475642323494\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9750727272900668\n",
      "\n",
      "epoch: 106, loss: 639.4258707761765\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9750363636537032\n",
      "\n",
      "epoch: 107, loss: 639.9234216213226\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9769454545801336\n",
      "\n",
      "epoch: 108, loss: 639.3706659078598\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9758727273074064\n",
      "\n",
      "epoch: 109, loss: 638.977961063385\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9768363636537032\n",
      "\n",
      "epoch: 110, loss: 639.3335100412369\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9750181818355214\n",
      "\n",
      "epoch: 111, loss: 638.367669582367\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9768181818355214\n",
      "\n",
      "epoch: 112, loss: 637.8914097547531\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9763272727619517\n",
      "\n",
      "epoch: 113, loss: 638.7061862945557\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9734909091082486\n",
      "\n",
      "epoch: 114, loss: 638.2329006195068\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9792181818355213\n",
      "\n",
      "epoch: 115, loss: 637.7343826293945\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9784545454892245\n",
      "\n",
      "epoch: 116, loss: 638.0544739961624\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.978854545471885\n",
      "\n",
      "epoch: 117, loss: 638.4217863082886\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9774727272900668\n",
      "\n",
      "epoch: 118, loss: 637.9713485240936\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9764000000173395\n",
      "\n",
      "epoch: 119, loss: 637.5938169956207\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9790181818355214\n",
      "\n",
      "epoch: 120, loss: 637.4989953041077\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9802181818355213\n",
      "\n",
      "epoch: 121, loss: 637.533277630806\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9810000000173396\n",
      "\n",
      "epoch: 122, loss: 637.2401041984558\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.979945454562794\n",
      "\n",
      "epoch: 123, loss: 637.7776474952698\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.980800000034679\n",
      "\n",
      "epoch: 124, loss: 637.8576704263687\n",
      "validation accuracy: 0.9234\n",
      "train accuracy: 0.9743272727619517\n",
      "\n",
      "epoch: 125, loss: 637.8445303440094\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9807818182164972\n",
      "\n",
      "epoch: 126, loss: 637.4411780834198\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9754727273074063\n",
      "\n",
      "epoch: 127, loss: 637.8632736206055\n",
      "validation accuracy: 0.9314\n",
      "train accuracy: 0.9801454545627941\n",
      "\n",
      "epoch: 128, loss: 637.7359801530838\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9750545454892245\n",
      "\n",
      "epoch: 129, loss: 637.9545931816101\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.9799818181991578\n",
      "\n",
      "epoch: 130, loss: 638.058818936348\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9788181818355214\n",
      "\n",
      "epoch: 131, loss: 638.6809303760529\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9770363636537032\n",
      "\n",
      "epoch: 132, loss: 638.7007608413696\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9772727272900668\n",
      "\n",
      "epoch: 133, loss: 638.3284125328064\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9799272727446122\n",
      "\n",
      "epoch: 134, loss: 639.9989215135574\n",
      "validation accuracy: 0.924\n",
      "train accuracy: 0.9755454545627941\n",
      "\n",
      "epoch: 135, loss: 638.1489697694778\n",
      "validation accuracy: 0.9238\n",
      "train accuracy: 0.974309090865742\n",
      "\n",
      "epoch: 136, loss: 637.6030215024948\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9802545454892245\n",
      "\n",
      "epoch: 137, loss: 637.6333748102188\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9781818181384694\n",
      "\n",
      "epoch: 138, loss: 637.747243642807\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9805454545801336\n",
      "\n",
      "epoch: 139, loss: 637.4406930208206\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.979800000034679\n",
      "\n",
      "epoch: 140, loss: 637.0677636861801\n",
      "validation accuracy: 0.9314\n",
      "train accuracy: 0.9808909091255882\n",
      "\n",
      "epoch: 141, loss: 636.9389536380768\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9824545454718849\n",
      "\n",
      "epoch: 142, loss: 636.9224851131439\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.9813636363809759\n",
      "\n",
      "epoch: 143, loss: 636.6922888755798\n",
      "validation accuracy: 0.9252\n",
      "train accuracy: 0.9770181818528609\n",
      "\n",
      "epoch: 144, loss: 639.419677734375\n",
      "validation accuracy: 0.9198\n",
      "train accuracy: 0.9748181818355214\n",
      "\n",
      "epoch: 145, loss: 640.4511271715164\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9751090909264304\n",
      "\n",
      "epoch: 146, loss: 639.0016593933105\n",
      "validation accuracy: 0.9194\n",
      "train accuracy: 0.9716000000346791\n",
      "\n",
      "epoch: 147, loss: 640.3313655853271\n",
      "validation accuracy: 0.9186\n",
      "train accuracy: 0.97050909094377\n",
      "\n",
      "epoch: 148, loss: 638.9320846796036\n",
      "validation accuracy: 0.9166\n",
      "train accuracy: 0.9737090908830817\n",
      "\n",
      "epoch: 149, loss: 639.2763129472733\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9810181818528609\n",
      "\n",
      "epoch: 150, loss: 638.9012275934219\n",
      "validation accuracy: 0.917\n",
      "train accuracy: 0.9652909090648998\n",
      "\n",
      "epoch: 151, loss: 640.4312992095947\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9787090909264304\n",
      "\n",
      "epoch: 152, loss: 638.1052864789963\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9798727272900668\n",
      "\n",
      "epoch: 153, loss: 638.41861140728\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9804909091082487\n",
      "\n",
      "epoch: 154, loss: 637.9472793340683\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9801818181991577\n",
      "\n",
      "epoch: 155, loss: 639.1412677764893\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.977054545471885\n",
      "\n",
      "epoch: 156, loss: 638.5888381004333\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9786000000173395\n",
      "\n",
      "epoch: 157, loss: 638.3732823133469\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9796181818355214\n",
      "\n",
      "epoch: 158, loss: 638.03366792202\n",
      "validation accuracy: 0.9242\n",
      "train accuracy: 0.9771818181991577\n",
      "\n",
      "epoch: 159, loss: 638.0894250869751\n",
      "validation accuracy: 0.9216\n",
      "train accuracy: 0.9754363636537031\n",
      "\n",
      "epoch: 160, loss: 637.3754367828369\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9804363636537031\n",
      "\n",
      "epoch: 161, loss: 638.1726932525635\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.970054545471885\n",
      "\n",
      "epoch: 162, loss: 638.1524482965469\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9782363636710427\n",
      "\n",
      "epoch: 163, loss: 639.2703846693039\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9767636363983154\n",
      "\n",
      "epoch: 164, loss: 640.1524293422699\n",
      "validation accuracy: 0.9154\n",
      "train accuracy: 0.9607272727446122\n",
      "\n",
      "epoch: 165, loss: 640.1456432342529\n",
      "validation accuracy: 0.9238\n",
      "train accuracy: 0.9730181818355214\n",
      "\n",
      "epoch: 166, loss: 641.2964377403259\n",
      "validation accuracy: 0.9206\n",
      "train accuracy: 0.9734000000346791\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 167, loss: 641.0612055063248\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9748727272900668\n",
      "\n",
      "epoch: 168, loss: 643.2631393671036\n",
      "validation accuracy: 0.9152\n",
      "train accuracy: 0.9603272727012634\n",
      "\n",
      "epoch: 169, loss: 643.7093979120255\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.9643090909264305\n",
      "\n",
      "epoch: 170, loss: 641.3470706939697\n",
      "validation accuracy: 0.922\n",
      "train accuracy: 0.9674909091255881\n",
      "\n",
      "epoch: 171, loss: 642.5090782642365\n",
      "validation accuracy: 0.9206\n",
      "train accuracy: 0.97010909094377\n",
      "\n",
      "epoch: 172, loss: 642.1633396148682\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9726363635930148\n",
      "\n",
      "epoch: 173, loss: 640.9710845947266\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9748363636710426\n",
      "\n",
      "epoch: 174, loss: 640.6948307752609\n",
      "validation accuracy: 0.9176\n",
      "train accuracy: 0.9656181817748329\n",
      "\n",
      "epoch: 175, loss: 643.438528418541\n",
      "validation accuracy: 0.9222\n",
      "train accuracy: 0.9733272727446123\n",
      "\n",
      "epoch: 176, loss: 640.6647441387177\n",
      "validation accuracy: 0.9252\n",
      "train accuracy: 0.9735454545627941\n",
      "\n",
      "epoch: 177, loss: 639.7283620834351\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9796727272900668\n",
      "\n",
      "epoch: 178, loss: 638.5935714244843\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9801636363983154\n",
      "\n",
      "epoch: 179, loss: 637.5438268184662\n",
      "validation accuracy: 0.9332\n",
      "train accuracy: 0.9789636363636364\n",
      "\n",
      "epoch: 180, loss: 637.9631711244583\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.9781636363809759\n",
      "\n",
      "epoch: 181, loss: 637.147544503212\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9807090909264304\n",
      "\n",
      "epoch: 182, loss: 637.0723043680191\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9814363635930148\n",
      "\n",
      "epoch: 183, loss: 636.6883059740067\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9793090909264305\n",
      "\n",
      "epoch: 184, loss: 637.0090820789337\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9818181818355214\n",
      "\n",
      "epoch: 185, loss: 637.3684440851212\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9805818182164973\n",
      "\n",
      "epoch: 186, loss: 638.3387851715088\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.975454545471885\n",
      "\n",
      "epoch: 187, loss: 639.6089285612106\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.9680909091255882\n",
      "\n",
      "epoch: 188, loss: 638.7976772785187\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9772\n",
      "\n",
      "epoch: 189, loss: 637.581750035286\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9747818182164972\n",
      "\n",
      "epoch: 190, loss: 638.7818987369537\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9708363636710428\n",
      "\n",
      "epoch: 191, loss: 638.8901681900024\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9792545454892245\n",
      "\n",
      "epoch: 192, loss: 638.372144818306\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9826181818355213\n",
      "\n",
      "epoch: 193, loss: 637.10537981987\n",
      "validation accuracy: 0.9268\n",
      "train accuracy: 0.9818181818528608\n",
      "\n",
      "epoch: 194, loss: 637.790876865387\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9741636363809759\n",
      "\n",
      "epoch: 195, loss: 639.5129907131195\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9741818181991577\n",
      "\n",
      "epoch: 196, loss: 637.9525524377823\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9812909091255881\n",
      "\n",
      "epoch: 197, loss: 636.9299594163895\n",
      "validation accuracy: 0.9204\n",
      "train accuracy: 0.9733090909437699\n",
      "\n",
      "epoch: 198, loss: 637.6938979625702\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9806000000173395\n",
      "\n",
      "epoch: 199, loss: 639.1749699115753\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.9729636363983154\n",
      "\n",
      "epoch: 200, loss: 637.9052858352661\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.9796181818355214\n",
      "\n",
      "epoch: 201, loss: 637.1188752651215\n",
      "validation accuracy: 0.9182\n",
      "train accuracy: 0.9740909090909091\n",
      "\n",
      "epoch: 202, loss: 637.3419697284698\n",
      "validation accuracy: 0.9328\n",
      "train accuracy: 0.982963636380976\n",
      "\n",
      "epoch: 203, loss: 636.2666709423065\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9836363636537032\n",
      "\n",
      "epoch: 204, loss: 639.1332223415375\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9801090909264304\n",
      "\n",
      "epoch: 205, loss: 639.7639592885971\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9771454545021057\n",
      "\n",
      "epoch: 206, loss: 640.1405198574066\n",
      "validation accuracy: 0.9306\n",
      "train accuracy: 0.9775818182164973\n",
      "\n",
      "epoch: 207, loss: 640.9698359966278\n",
      "validation accuracy: 0.9268\n",
      "train accuracy: 0.9696000000173395\n",
      "\n",
      "epoch: 208, loss: 639.619656085968\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9777090909264304\n",
      "\n",
      "epoch: 209, loss: 643.1850478649139\n",
      "validation accuracy: 0.922\n",
      "train accuracy: 0.96990909094377\n",
      "\n",
      "epoch: 210, loss: 639.4002224206924\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9774909091082487\n",
      "\n",
      "epoch: 211, loss: 638.0802365541458\n",
      "validation accuracy: 0.9234\n",
      "train accuracy: 0.9786727273074063\n",
      "\n",
      "epoch: 212, loss: 637.3132857084274\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9813272727619518\n",
      "\n",
      "epoch: 213, loss: 636.5689966678619\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9824181818355213\n",
      "\n",
      "epoch: 214, loss: 637.7114263772964\n",
      "validation accuracy: 0.9226\n",
      "train accuracy: 0.9773454545627941\n",
      "\n",
      "epoch: 215, loss: 638.4933577775955\n",
      "validation accuracy: 0.923\n",
      "train accuracy: 0.9737272727012635\n",
      "\n",
      "epoch: 216, loss: 638.7325587272644\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9786909091082486\n",
      "\n",
      "epoch: 217, loss: 637.3279169797897\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.977054545471885\n",
      "\n",
      "epoch: 218, loss: 638.3776457309723\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9788363636537032\n",
      "\n",
      "epoch: 219, loss: 636.9608714580536\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9817272727446122\n",
      "\n",
      "epoch: 220, loss: 636.8774225711823\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.9813454545627941\n",
      "\n",
      "epoch: 221, loss: 636.5158103704453\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9838181818355214\n",
      "\n",
      "epoch: 222, loss: 636.8541451692581\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9786727272900668\n",
      "\n",
      "epoch: 223, loss: 641.058545589447\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9779636363809759\n",
      "\n",
      "epoch: 224, loss: 639.7458649873734\n",
      "validation accuracy: 0.9134\n",
      "train accuracy: 0.9558181818095121\n",
      "\n",
      "epoch: 225, loss: 641.0371216535568\n",
      "validation accuracy: 0.9174\n",
      "train accuracy: 0.9694909090475603\n",
      "\n",
      "epoch: 226, loss: 639.3043022155762\n",
      "validation accuracy: 0.9256\n",
      "train accuracy: 0.9785272727446123\n",
      "\n",
      "epoch: 227, loss: 638.8321306705475\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9793454545801336\n",
      "\n",
      "epoch: 228, loss: 637.8495976924896\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9807090909264304\n",
      "\n",
      "epoch: 229, loss: 637.3430896997452\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.980963636380976\n",
      "\n",
      "epoch: 230, loss: 638.0460443496704\n",
      "validation accuracy: 0.9196\n",
      "train accuracy: 0.9740181818528609\n",
      "\n",
      "epoch: 231, loss: 638.1837075948715\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9803818181991577\n",
      "\n",
      "epoch: 232, loss: 639.0439095497131\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9802363636537031\n",
      "\n",
      "epoch: 233, loss: 640.8302627801895\n",
      "validation accuracy: 0.9252\n",
      "train accuracy: 0.9765818181991577\n",
      "\n",
      "epoch: 234, loss: 638.5168993473053\n",
      "validation accuracy: 0.9248\n",
      "train accuracy: 0.9756000000346791\n",
      "\n",
      "epoch: 235, loss: 638.7054274082184\n",
      "validation accuracy: 0.9214\n",
      "train accuracy: 0.9762909091255881\n",
      "\n",
      "epoch: 236, loss: 638.0281673669815\n",
      "validation accuracy: 0.9238\n",
      "train accuracy: 0.9784545454892245\n",
      "\n",
      "epoch: 237, loss: 636.8745567798615\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9814545454892245\n",
      "\n",
      "epoch: 238, loss: 636.5115770101547\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9837090909264304\n",
      "\n",
      "epoch: 239, loss: 636.6484425067902\n",
      "validation accuracy: 0.9186\n",
      "train accuracy: 0.9718363635930148\n",
      "\n",
      "epoch: 240, loss: 637.6939527988434\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9801818181991577\n",
      "\n",
      "epoch: 241, loss: 639.5802319049835\n",
      "validation accuracy: 0.9148\n",
      "train accuracy: 0.9653090909264305\n",
      "\n",
      "epoch: 242, loss: 638.7628961801529\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9790181818528609\n",
      "\n",
      "epoch: 243, loss: 637.1619184017181\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9810181818355214\n",
      "\n",
      "epoch: 244, loss: 636.0957052707672\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9795272727272727\n",
      "\n",
      "epoch: 245, loss: 636.2268390655518\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9812909091082487\n",
      "\n",
      "epoch: 246, loss: 635.742101430893\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9839818181384693\n",
      "\n",
      "epoch: 247, loss: 636.1201393604279\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9834909091255881\n",
      "\n",
      "epoch: 248, loss: 635.7475372552872\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9853636363983155\n",
      "\n",
      "epoch: 249, loss: 635.829087972641\n",
      "validation accuracy: 0.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9800363636710427\n",
      "\n",
      "epoch: 250, loss: 636.1326987743378\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9812909091255881\n",
      "\n",
      "epoch: 251, loss: 635.9586811065674\n",
      "validation accuracy: 0.9216\n",
      "train accuracy: 0.9798727273074064\n",
      "\n",
      "epoch: 252, loss: 635.7870434522629\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9845636363809759\n",
      "\n",
      "epoch: 253, loss: 635.513965010643\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9855454545627941\n",
      "\n",
      "epoch: 254, loss: 636.3369553089142\n",
      "validation accuracy: 0.9206\n",
      "train accuracy: 0.9800909091255882\n",
      "\n",
      "epoch: 255, loss: 636.2676895856857\n",
      "validation accuracy: 0.9204\n",
      "train accuracy: 0.9819818181384693\n",
      "\n",
      "epoch: 256, loss: 635.9756108522415\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9851818181991577\n",
      "\n",
      "epoch: 257, loss: 637.3262730836868\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9801272727446123\n",
      "\n",
      "epoch: 258, loss: 636.482808470726\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.979745454562794\n",
      "\n",
      "epoch: 259, loss: 636.1298840045929\n",
      "validation accuracy: 0.9248\n",
      "train accuracy: 0.980000000034679\n",
      "\n",
      "epoch: 260, loss: 636.9136738777161\n",
      "validation accuracy: 0.9206\n",
      "train accuracy: 0.974018181774833\n",
      "\n",
      "epoch: 261, loss: 636.3502875566483\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9855818182164973\n",
      "\n",
      "epoch: 262, loss: 634.4721264839172\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9846363636537032\n",
      "\n",
      "epoch: 263, loss: 635.7298288345337\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9851272727446123\n",
      "\n",
      "epoch: 264, loss: 635.0034065246582\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9845090909264305\n",
      "\n",
      "epoch: 265, loss: 635.0875068902969\n",
      "validation accuracy: 0.9232\n",
      "train accuracy: 0.9776727272293785\n",
      "\n",
      "epoch: 266, loss: 636.030436038971\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9856000000173395\n",
      "\n",
      "epoch: 267, loss: 634.7944779396057\n",
      "validation accuracy: 0.9234\n",
      "train accuracy: 0.9796727273074063\n",
      "\n",
      "epoch: 268, loss: 635.9214811325073\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9848727273074064\n",
      "\n",
      "epoch: 269, loss: 636.1716964244843\n",
      "validation accuracy: 0.9268\n",
      "train accuracy: 0.9833818181991577\n",
      "\n",
      "epoch: 270, loss: 635.4415947198868\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9827272727446122\n",
      "\n",
      "epoch: 271, loss: 635.6198107004166\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9860000000173396\n",
      "\n",
      "epoch: 272, loss: 635.7105033397675\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9835090909437699\n",
      "\n",
      "epoch: 273, loss: 635.3242834806442\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9828909091082486\n",
      "\n",
      "epoch: 274, loss: 636.0178290605545\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9850727272900668\n",
      "\n",
      "epoch: 275, loss: 635.9519203901291\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9839090909264304\n",
      "\n",
      "epoch: 276, loss: 635.4628819227219\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9856181818355213\n",
      "\n",
      "epoch: 277, loss: 635.6340795755386\n",
      "validation accuracy: 0.9248\n",
      "train accuracy: 0.9817636363983154\n",
      "\n",
      "epoch: 278, loss: 636.2882343530655\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9818363636537032\n",
      "\n",
      "epoch: 279, loss: 637.6703200340271\n",
      "validation accuracy: 0.9216\n",
      "train accuracy: 0.9783454545801337\n",
      "\n",
      "epoch: 280, loss: 637.0968302488327\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9834000000173395\n",
      "\n",
      "epoch: 281, loss: 635.1860888004303\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.982745454562794\n",
      "\n",
      "epoch: 282, loss: 635.11541056633\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9852909091082486\n",
      "\n",
      "epoch: 283, loss: 634.8381848335266\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9855636363809759\n",
      "\n",
      "epoch: 284, loss: 635.6568641662598\n",
      "validation accuracy: 0.9204\n",
      "train accuracy: 0.9775818181991577\n",
      "\n",
      "epoch: 285, loss: 636.0488173961639\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9808727272900668\n",
      "\n",
      "epoch: 286, loss: 635.248236656189\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9784909091082487\n",
      "\n",
      "epoch: 287, loss: 635.6285264492035\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9850909091082486\n",
      "\n",
      "epoch: 288, loss: 635.1997437477112\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9842000000173395\n",
      "\n",
      "epoch: 289, loss: 635.3189522027969\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9854545454718849\n",
      "\n",
      "epoch: 290, loss: 634.1639804840088\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.987054545471885\n",
      "\n",
      "epoch: 291, loss: 634.6040163040161\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9842727272900668\n",
      "\n",
      "epoch: 292, loss: 634.7672976255417\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9835272727446123\n",
      "\n",
      "epoch: 293, loss: 634.5469355583191\n",
      "validation accuracy: 0.9256\n",
      "train accuracy: 0.9870000000173396\n",
      "\n",
      "epoch: 294, loss: 634.0176150798798\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.98690909094377\n",
      "\n",
      "epoch: 295, loss: 634.2729535102844\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9868000000173396\n",
      "\n",
      "epoch: 296, loss: 634.2153601646423\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9873090909264305\n",
      "\n",
      "epoch: 297, loss: 634.5500999689102\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9870181818355214\n",
      "\n",
      "epoch: 298, loss: 634.1950685977936\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9871272727446122\n",
      "\n",
      "epoch: 299, loss: 633.964472413063\n",
      "validation accuracy: 0.926\n",
      "train accuracy: 0.9863090909264305\n",
      "\n",
      "epoch: 300, loss: 633.929193854332\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9879272727446122\n",
      "\n",
      "epoch: 301, loss: 633.8087832927704\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.987854545471885\n",
      "\n",
      "epoch: 302, loss: 634.4349865913391\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.986963636380976\n",
      "\n",
      "epoch: 303, loss: 633.8749388456345\n",
      "validation accuracy: 0.9306\n",
      "train accuracy: 0.9878909091082486\n",
      "\n",
      "epoch: 304, loss: 633.8380162715912\n",
      "validation accuracy: 0.9318\n",
      "train accuracy: 0.9868363636537032\n",
      "\n",
      "epoch: 305, loss: 634.2251398563385\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9838000000173396\n",
      "\n",
      "epoch: 306, loss: 634.0362123250961\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9875818181991577\n",
      "\n",
      "epoch: 307, loss: 634.0140109062195\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9873272727446123\n",
      "\n",
      "epoch: 308, loss: 634.6163282394409\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9845636363809759\n",
      "\n",
      "epoch: 309, loss: 634.0174674987793\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9828363636537032\n",
      "\n",
      "epoch: 310, loss: 634.2731392383575\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9871090909264304\n",
      "\n",
      "epoch: 311, loss: 634.3468364477158\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9865818181991577\n",
      "\n",
      "epoch: 312, loss: 634.232351899147\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9861272727446123\n",
      "\n",
      "epoch: 313, loss: 633.937898516655\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.9881090909264304\n",
      "\n",
      "epoch: 314, loss: 634.2471660375595\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9858727272900668\n",
      "\n",
      "epoch: 315, loss: 633.6988773345947\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9860909091082486\n",
      "\n",
      "epoch: 316, loss: 633.9339500665665\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9869272727446122\n",
      "\n",
      "epoch: 317, loss: 633.6904420852661\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9880727273074064\n",
      "\n",
      "epoch: 318, loss: 634.9111685752869\n",
      "validation accuracy: 0.924\n",
      "train accuracy: 0.9849272726839239\n",
      "\n",
      "epoch: 319, loss: 634.2859010696411\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9865090909264305\n",
      "\n",
      "epoch: 320, loss: 634.4914494752884\n",
      "validation accuracy: 0.9318\n",
      "train accuracy: 0.987854545471885\n",
      "\n",
      "epoch: 321, loss: 634.2471190690994\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9855636363809759\n",
      "\n",
      "epoch: 322, loss: 634.9055284261703\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9847636363809759\n",
      "\n",
      "epoch: 323, loss: 634.4997285604477\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9873272727446123\n",
      "\n",
      "epoch: 324, loss: 633.7773661613464\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9874000000173395\n",
      "\n",
      "epoch: 325, loss: 633.8336926698685\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.987654545471885\n",
      "\n",
      "epoch: 326, loss: 634.1629637479782\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9858909091255882\n",
      "\n",
      "epoch: 327, loss: 634.5713714361191\n",
      "validation accuracy: 0.9258\n",
      "train accuracy: 0.9856363636537032\n",
      "\n",
      "epoch: 328, loss: 634.2956439256668\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.9878000000173396\n",
      "\n",
      "epoch: 329, loss: 634.4955012798309\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.9822181818528609\n",
      "\n",
      "epoch: 330, loss: 635.8780437707901\n",
      "validation accuracy: 0.9268\n",
      "train accuracy: 0.985745454562794\n",
      "\n",
      "epoch: 331, loss: 635.0218329429626\n",
      "validation accuracy: 0.924\n",
      "train accuracy: 0.981745454562794\n",
      "\n",
      "epoch: 332, loss: 634.0773514509201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9880363636710427\n",
      "\n",
      "epoch: 333, loss: 634.356928229332\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9887818181991577\n",
      "\n",
      "epoch: 334, loss: 633.7341378927231\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9872181818355213\n",
      "\n",
      "epoch: 335, loss: 633.5606949329376\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9884363636537031\n",
      "\n",
      "epoch: 336, loss: 633.6593655347824\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.988654545471885\n",
      "\n",
      "epoch: 337, loss: 633.4032567739487\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9869090909264304\n",
      "\n",
      "epoch: 338, loss: 633.5929182767868\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9883454545627941\n",
      "\n",
      "epoch: 339, loss: 634.9832262992859\n",
      "validation accuracy: 0.9244\n",
      "train accuracy: 0.9819090909264304\n",
      "\n",
      "epoch: 340, loss: 636.2282348871231\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9877272727446123\n",
      "\n",
      "epoch: 341, loss: 633.6369588375092\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9856181818355213\n",
      "\n",
      "epoch: 342, loss: 634.4739371538162\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9824545454892245\n",
      "\n",
      "epoch: 343, loss: 634.1625638008118\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9874363636537031\n",
      "\n",
      "epoch: 344, loss: 634.1323783397675\n",
      "validation accuracy: 0.9226\n",
      "train accuracy: 0.986254545471885\n",
      "\n",
      "epoch: 345, loss: 634.2397240400314\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9854909091082487\n",
      "\n",
      "epoch: 346, loss: 633.4722142219543\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.9881272727446122\n",
      "\n",
      "epoch: 347, loss: 634.1351602077484\n",
      "validation accuracy: 0.9238\n",
      "train accuracy: 0.9869818181991578\n",
      "\n",
      "epoch: 348, loss: 634.0436017513275\n",
      "validation accuracy: 0.9248\n",
      "train accuracy: 0.9864545454718849\n",
      "\n",
      "epoch: 349, loss: 633.8184236288071\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9879818181991578\n",
      "\n",
      "epoch: 350, loss: 633.6689486503601\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.988254545471885\n",
      "\n",
      "epoch: 351, loss: 633.7702989578247\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9885636363809759\n",
      "\n",
      "epoch: 352, loss: 634.0215252637863\n",
      "validation accuracy: 0.9268\n",
      "train accuracy: 0.9860727272900668\n",
      "\n",
      "epoch: 353, loss: 633.453649520874\n",
      "validation accuracy: 0.932\n",
      "train accuracy: 0.9887090909264304\n",
      "\n",
      "epoch: 354, loss: 633.8190935850143\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.9878181818355214\n",
      "\n",
      "epoch: 355, loss: 633.9814159870148\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9849272727446122\n",
      "\n",
      "epoch: 356, loss: 633.8056455850601\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9893636363809759\n",
      "\n",
      "epoch: 357, loss: 633.7688320875168\n",
      "validation accuracy: 0.9306\n",
      "train accuracy: 0.9872909091082486\n",
      "\n",
      "epoch: 358, loss: 633.2410899400711\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9892909091082486\n",
      "\n",
      "epoch: 359, loss: 633.1443966627121\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9894363636537031\n",
      "\n",
      "epoch: 360, loss: 633.1788107156754\n",
      "validation accuracy: 0.9246\n",
      "train accuracy: 0.9880909091082486\n",
      "\n",
      "epoch: 361, loss: 633.1148028373718\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9896181818355213\n",
      "\n",
      "epoch: 362, loss: 633.1907459497452\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9888000000173396\n",
      "\n",
      "epoch: 363, loss: 633.7861475944519\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.9850363636710427\n",
      "\n",
      "epoch: 364, loss: 633.6285375356674\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9877454545801336\n",
      "\n",
      "epoch: 365, loss: 633.5581817626953\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9881454545627941\n",
      "\n",
      "epoch: 366, loss: 633.3242801427841\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.988854545471885\n",
      "\n",
      "epoch: 367, loss: 632.9205523729324\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.9893818181991577\n",
      "\n",
      "epoch: 368, loss: 633.3893206119537\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9846181818528609\n",
      "\n",
      "epoch: 369, loss: 634.1885645389557\n",
      "validation accuracy: 0.9306\n",
      "train accuracy: 0.9882909091082486\n",
      "\n",
      "epoch: 370, loss: 634.3061164617538\n",
      "validation accuracy: 0.9232\n",
      "train accuracy: 0.9864181818528609\n",
      "\n",
      "epoch: 371, loss: 633.6535075902939\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.987654545471885\n",
      "\n",
      "epoch: 372, loss: 633.3336045742035\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9887090909264304\n",
      "\n",
      "epoch: 373, loss: 633.6714581251144\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9882181818355213\n",
      "\n",
      "epoch: 374, loss: 634.3245649337769\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9862000000173395\n",
      "\n",
      "epoch: 375, loss: 634.3454215526581\n",
      "validation accuracy: 0.9282\n",
      "train accuracy: 0.9880363636537032\n",
      "\n",
      "epoch: 376, loss: 633.7366247177124\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9889818181991578\n",
      "\n",
      "epoch: 377, loss: 633.6092495918274\n",
      "validation accuracy: 0.9314\n",
      "train accuracy: 0.9871454545627941\n",
      "\n",
      "epoch: 378, loss: 633.5587242841721\n",
      "validation accuracy: 0.9254\n",
      "train accuracy: 0.9856909091082486\n",
      "\n",
      "epoch: 379, loss: 633.7758574485779\n",
      "validation accuracy: 0.9314\n",
      "train accuracy: 0.9889818181991578\n",
      "\n",
      "epoch: 380, loss: 633.3151177167892\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9885818181991577\n",
      "\n",
      "epoch: 381, loss: 633.9691324234009\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9882181818355213\n",
      "\n",
      "epoch: 382, loss: 633.669548034668\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.9838181817748329\n",
      "\n",
      "epoch: 383, loss: 634.4896891117096\n",
      "validation accuracy: 0.9226\n",
      "train accuracy: 0.9830727272900668\n",
      "\n",
      "epoch: 384, loss: 634.6686426401138\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9866181818355213\n",
      "\n",
      "epoch: 385, loss: 633.7309991121292\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.987963636380976\n",
      "\n",
      "epoch: 386, loss: 633.8705823421478\n",
      "validation accuracy: 0.931\n",
      "train accuracy: 0.9883636363809759\n",
      "\n",
      "epoch: 387, loss: 634.6634033918381\n",
      "validation accuracy: 0.9272\n",
      "train accuracy: 0.9874909091082487\n",
      "\n",
      "epoch: 388, loss: 634.7584413290024\n",
      "validation accuracy: 0.9274\n",
      "train accuracy: 0.9856727272900668\n",
      "\n",
      "epoch: 389, loss: 634.1525396108627\n",
      "validation accuracy: 0.9294\n",
      "train accuracy: 0.9867272727446122\n",
      "\n",
      "epoch: 390, loss: 635.054044008255\n",
      "validation accuracy: 0.9228\n",
      "train accuracy: 0.9829272727619518\n",
      "\n",
      "epoch: 391, loss: 635.6361199617386\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9860363636710427\n",
      "\n",
      "epoch: 392, loss: 634.7833539247513\n",
      "validation accuracy: 0.9236\n",
      "train accuracy: 0.9837090909264304\n",
      "\n",
      "epoch: 393, loss: 636.7063820362091\n",
      "validation accuracy: 0.9234\n",
      "train accuracy: 0.9819272727619518\n",
      "\n",
      "epoch: 394, loss: 635.657986164093\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9834545454111966\n",
      "\n",
      "epoch: 395, loss: 635.7748568058014\n",
      "validation accuracy: 0.925\n",
      "train accuracy: 0.9826000000346791\n",
      "\n",
      "epoch: 396, loss: 634.572466135025\n",
      "validation accuracy: 0.9234\n",
      "train accuracy: 0.982800000034679\n",
      "\n",
      "epoch: 397, loss: 633.804527759552\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9847272727446122\n",
      "\n",
      "epoch: 398, loss: 633.3842432498932\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9867090909264304\n",
      "\n",
      "epoch: 399, loss: 634.7556763887405\n",
      "validation accuracy: 0.9264\n",
      "train accuracy: 0.9839090909264304\n",
      "\n",
      "epoch: 400, loss: 634.5625313520432\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.9867090909264304\n",
      "\n",
      "epoch: 401, loss: 633.7220420837402\n",
      "validation accuracy: 0.9288\n",
      "train accuracy: 0.9890000000173396\n",
      "\n",
      "epoch: 402, loss: 633.5869450569153\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9887818182164972\n",
      "\n",
      "epoch: 403, loss: 632.9886649847031\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9894545454718849\n",
      "\n",
      "epoch: 404, loss: 632.9916338920593\n",
      "validation accuracy: 0.9332\n",
      "train accuracy: 0.9891818181991577\n",
      "\n",
      "epoch: 405, loss: 633.0347679853439\n",
      "validation accuracy: 0.9262\n",
      "train accuracy: 0.98690909094377\n",
      "\n",
      "epoch: 406, loss: 632.9511976242065\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9899818181991578\n",
      "\n",
      "epoch: 407, loss: 633.0023771524429\n",
      "validation accuracy: 0.9272\n",
      "train accuracy: 0.9884545454718849\n",
      "\n",
      "epoch: 408, loss: 633.4328355789185\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9894000000346791\n",
      "\n",
      "epoch: 409, loss: 632.9775011539459\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9892181818355213\n",
      "\n",
      "epoch: 410, loss: 632.99846804142\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9897636363809759\n",
      "\n",
      "epoch: 411, loss: 632.7789975404739\n",
      "validation accuracy: 0.9344\n",
      "train accuracy: 0.9895636363983155\n",
      "\n",
      "epoch: 412, loss: 633.1261769533157\n",
      "validation accuracy: 0.928\n",
      "train accuracy: 0.9892000000346791\n",
      "\n",
      "epoch: 413, loss: 632.824657201767\n",
      "validation accuracy: 0.929\n",
      "train accuracy: 0.98970909094377\n",
      "\n",
      "epoch: 414, loss: 632.8092585802078\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9898181818355214\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 415, loss: 633.3013756275177\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9888727273074064\n",
      "\n",
      "epoch: 416, loss: 633.0234361886978\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9896363636537032\n",
      "\n",
      "epoch: 417, loss: 632.9759377241135\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9895272727446123\n",
      "\n",
      "epoch: 418, loss: 632.6938010454178\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9896363636537032\n",
      "\n",
      "epoch: 419, loss: 632.9269939661026\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9899090909264304\n",
      "\n",
      "epoch: 420, loss: 632.6132048368454\n",
      "validation accuracy: 0.927\n",
      "train accuracy: 0.9897636363809759\n",
      "\n",
      "epoch: 421, loss: 632.5600371360779\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.990054545471885\n",
      "\n",
      "epoch: 422, loss: 632.6631441116333\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.98930909094377\n",
      "\n",
      "epoch: 423, loss: 632.5498661994934\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9897636363809759\n",
      "\n",
      "epoch: 424, loss: 632.7702032327652\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9902181818355213\n",
      "\n",
      "epoch: 425, loss: 632.5049878358841\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9904545454718849\n",
      "\n",
      "epoch: 426, loss: 632.3625366687775\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9906181818355213\n",
      "\n",
      "epoch: 427, loss: 632.4234719276428\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9904363636710427\n",
      "\n",
      "epoch: 428, loss: 632.4021855592728\n",
      "validation accuracy: 0.9314\n",
      "train accuracy: 0.9905818182164973\n",
      "\n",
      "epoch: 429, loss: 632.4350250959396\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.990654545471885\n",
      "\n",
      "epoch: 430, loss: 632.2934606075287\n",
      "validation accuracy: 0.9306\n",
      "train accuracy: 0.9906727272900668\n",
      "\n",
      "epoch: 431, loss: 632.4822537899017\n",
      "validation accuracy: 0.9338\n",
      "train accuracy: 0.9904727272900669\n",
      "\n",
      "epoch: 432, loss: 632.4577847719193\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9902909091082486\n",
      "\n",
      "epoch: 433, loss: 632.4704550504684\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9905272727446123\n",
      "\n",
      "epoch: 434, loss: 632.3681210279465\n",
      "validation accuracy: 0.9332\n",
      "train accuracy: 0.9906181818355213\n",
      "\n",
      "epoch: 435, loss: 632.3480719327927\n",
      "validation accuracy: 0.9344\n",
      "train accuracy: 0.9906181818355213\n",
      "\n",
      "epoch: 436, loss: 632.3351315259933\n",
      "validation accuracy: 0.9338\n",
      "train accuracy: 0.9906727272900668\n",
      "\n",
      "epoch: 437, loss: 632.3132035732269\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9907090909264304\n",
      "\n",
      "epoch: 438, loss: 632.2979611158371\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.9907090909264304\n",
      "\n",
      "epoch: 439, loss: 632.3310655355453\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.990654545471885\n",
      "\n",
      "epoch: 440, loss: 632.3245515823364\n",
      "validation accuracy: 0.932\n",
      "train accuracy: 0.9886727272900668\n",
      "\n",
      "epoch: 441, loss: 632.6733310222626\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9905636363809759\n",
      "\n",
      "epoch: 442, loss: 632.6967298984528\n",
      "validation accuracy: 0.9296\n",
      "train accuracy: 0.9903090909264305\n",
      "\n",
      "epoch: 443, loss: 632.532998085022\n",
      "validation accuracy: 0.9266\n",
      "train accuracy: 0.9901636363809759\n",
      "\n",
      "epoch: 444, loss: 632.7263141870499\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9902000000173395\n",
      "\n",
      "epoch: 445, loss: 632.6533068418503\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.989854545471885\n",
      "\n",
      "epoch: 446, loss: 632.607835650444\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9898000000173396\n",
      "\n",
      "epoch: 447, loss: 632.4859974384308\n",
      "validation accuracy: 0.9276\n",
      "train accuracy: 0.9902909091082486\n",
      "\n",
      "epoch: 448, loss: 632.5594602823257\n",
      "validation accuracy: 0.9278\n",
      "train accuracy: 0.9902363636537032\n",
      "\n",
      "epoch: 449, loss: 632.3748511075974\n",
      "validation accuracy: 0.9272\n",
      "train accuracy: 0.989854545471885\n",
      "\n",
      "epoch: 450, loss: 632.3904913663864\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9905818181991577\n",
      "\n",
      "epoch: 451, loss: 632.3533152341843\n",
      "validation accuracy: 0.9324\n",
      "train accuracy: 0.9906727272900668\n",
      "\n",
      "epoch: 452, loss: 632.410841345787\n",
      "validation accuracy: 0.9286\n",
      "train accuracy: 0.9906363636537032\n",
      "\n",
      "epoch: 453, loss: 632.4272563457489\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9905818181991577\n",
      "\n",
      "epoch: 454, loss: 632.388454914093\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9904545454718849\n",
      "\n",
      "epoch: 455, loss: 632.4631088972092\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9903272727446123\n",
      "\n",
      "epoch: 456, loss: 632.5415352582932\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9901272727446122\n",
      "\n",
      "epoch: 457, loss: 632.6382724046707\n",
      "validation accuracy: 0.9292\n",
      "train accuracy: 0.9892727272900668\n",
      "\n",
      "epoch: 458, loss: 632.4914141893387\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9901090909264304\n",
      "\n",
      "epoch: 459, loss: 632.5993884801865\n",
      "validation accuracy: 0.9284\n",
      "train accuracy: 0.9902181818355213\n",
      "\n",
      "epoch: 460, loss: 632.5848199129105\n",
      "validation accuracy: 0.9298\n",
      "train accuracy: 0.9904363636537031\n",
      "\n",
      "epoch: 461, loss: 632.3902564048767\n",
      "validation accuracy: 0.9328\n",
      "train accuracy: 0.9906000000173395\n",
      "\n",
      "epoch: 462, loss: 632.6732615232468\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9884727272900669\n",
      "\n",
      "epoch: 463, loss: 632.7384940385818\n",
      "validation accuracy: 0.9328\n",
      "train accuracy: 0.9904363636537031\n",
      "\n",
      "epoch: 464, loss: 632.741696357727\n",
      "validation accuracy: 0.9304\n",
      "train accuracy: 0.9903090909264305\n",
      "\n",
      "epoch: 465, loss: 632.4904617071152\n",
      "validation accuracy: 0.93\n",
      "train accuracy: 0.9904727272900669\n",
      "\n",
      "epoch: 466, loss: 632.5275112390518\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9905090909264305\n",
      "\n",
      "epoch: 467, loss: 632.4201270341873\n",
      "validation accuracy: 0.9312\n",
      "train accuracy: 0.9900727272900668\n",
      "\n",
      "epoch: 468, loss: 632.3475255966187\n",
      "validation accuracy: 0.9338\n",
      "train accuracy: 0.9901090909264304\n",
      "\n",
      "epoch: 469, loss: 632.322193145752\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.9908181818355214\n",
      "\n",
      "epoch: 470, loss: 632.2947841882706\n",
      "validation accuracy: 0.9308\n",
      "train accuracy: 0.9907636363809759\n",
      "\n",
      "epoch: 471, loss: 632.3133664131165\n",
      "validation accuracy: 0.9302\n",
      "train accuracy: 0.9905636363809759\n",
      "\n",
      "epoch: 472, loss: 632.3298285007477\n",
      "validation accuracy: 0.9316\n",
      "train accuracy: 0.9908000000173396\n",
      "\n",
      "epoch: 473, loss: 632.3135507106781\n",
      "validation accuracy: 0.934\n",
      "train accuracy: 0.9907454545801336\n",
      "\n",
      "epoch: 474, loss: 632.2701992988586\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9908181818355214\n",
      "\n",
      "epoch: 475, loss: 632.2439117431641\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9908000000173396\n",
      "\n",
      "epoch: 476, loss: 632.240947842598\n",
      "validation accuracy: 0.934\n",
      "train accuracy: 0.9908727272900668\n",
      "\n",
      "epoch: 477, loss: 632.2149693965912\n",
      "validation accuracy: 0.934\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 478, loss: 632.207425236702\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 479, loss: 632.2075771093369\n",
      "validation accuracy: 0.9328\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 480, loss: 632.2150211334229\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 481, loss: 632.20803129673\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 482, loss: 632.2148789167404\n",
      "validation accuracy: 0.932\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 483, loss: 632.2080068588257\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 484, loss: 632.2119145393372\n",
      "validation accuracy: 0.9322\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 485, loss: 632.2117681503296\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 486, loss: 632.2114729881287\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 487, loss: 632.2112139463425\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 488, loss: 632.2076181173325\n",
      "validation accuracy: 0.9328\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 489, loss: 632.211403131485\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 490, loss: 632.2074344158173\n",
      "validation accuracy: 0.9334\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 491, loss: 632.211563706398\n",
      "validation accuracy: 0.9338\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 492, loss: 632.2080385684967\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 493, loss: 632.2148119211197\n",
      "validation accuracy: 0.9338\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 494, loss: 632.207961678505\n",
      "validation accuracy: 0.9332\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 495, loss: 632.2078263759613\n",
      "validation accuracy: 0.9336\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 496, loss: 632.2111449241638\n",
      "validation accuracy: 0.934\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 497, loss: 632.2081118822098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.9334\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 498, loss: 632.2112966775894\n",
      "validation accuracy: 0.933\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 499, loss: 632.2077242136002\n",
      "validation accuracy: 0.9326\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "epoch: 500, loss: 632.211510181427\n",
      "validation accuracy: 0.9334\n",
      "train accuracy: 0.9908909091082486\n",
      "\n",
      "training finished.\n",
      "test accuracy: 0.9258\n",
      "Training validation set accuracy graph:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f081f9e69e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
